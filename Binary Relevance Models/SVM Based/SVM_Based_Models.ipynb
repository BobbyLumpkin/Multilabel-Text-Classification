{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Filename: SVM_Based_Models.ipynb\n",
    "#\n",
    "# Purpose: Multi-label Text-categorization via binary relevance, using support vector machines as base classifiers\n",
    "#\n",
    "# Author(s): Bobby (Robert) Lumpkin\n",
    "#\n",
    "# Library Dependencies: numpy, pandas, scikit-learn\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputClassifier \n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load\n",
    "import sys\n",
    "sys.path.append('../../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function \n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\rober\\\\OneDrive\\\\Documents\\\\Multilabel-Text-Classification\\\\Binary Relevance Models\\\\SVM Based')  \n",
    "## Replace with above path with appropriate working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Classification Using Binary Relevance Models\n",
    "\n",
    "Arguably, the most intuitive among multilabel modeling approaches is what's referred to as \"binary relevance\". This approach works by decomposing the multi-label learning task into a number of independent binary learning tasks (one per class label) (Zhang et al. [2018]). Binary Relevance methods are often criticized in the literature because of their label independence assumption, producing a potential weakness of ignoring correlations among labels (Luaces et al. [2012]). In this notebook, we'll explore binary relevance models built using differenct base classifiers. Later, in other notebooks, we'll train more novel approaches for comparison.\n",
    "\n",
    "For the other base classifiers we consider (GBTs and kNN) we will consider different threshold function methods: constant vs. using a learned threshold function. Learning threshold functions has the advantage of allowing for different instances to possess different thresholds. This can be useful when a model either cannot consistenty separate true from false labels around a constant value OR when sufficient training is resource intensive. In many instances, a model may learn to separate true from false labels earlier in the training process than it learns to separate about a constant threshold. We do not apply these methods here, since we do not generate probability estimates.\n",
    "\n",
    "Additionally, each of the models will be trained using both the separable principal component scores and the autoencoder encodings derived in 'Preprocessing and Dimension Reduction/tfidf_Dimension_Reduction.ipynb'. Below, we'll load the data and compute one baseline for validating our models according to Hamming Loss. Namely, since our labels are sparse, we'll compute the validation Hamming Loss associated with a constant zero classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the 'separable' PC features\n",
    "npzfile = np.load(\"../../Data/tfidf_PC_separable.npz\")\n",
    "X_sepPCs_train = npzfile[\"X_sepPCs_train\"]\n",
    "X_sepPCs_test = npzfile[\"X_sepPCs_test\"]\n",
    "\n",
    "## Load the autoencoder encodings\n",
    "npzfile = np.load(\"../../Data/tfidf_encoded_data.npz\")\n",
    "encoded_train = npzfile[\"encoded_train\"]\n",
    "encoded_test = npzfile[\"encoded_test\"]\n",
    "\n",
    "## Load the labels\n",
    "Y_train = npzfile[\"Y_train\"]\n",
    "Y_test = npzfile[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013779397151374627"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute the validation Hamming Loss for a constant zero classifier (used as silly baseline for sparse labels)\n",
    "prop_one_bpmll = np.sum(Y_test == 1) / (Y_test.shape[0] * Y_test.shape[1])\n",
    "prop_one_bpmll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Classifier: Support Vector Machine\n",
    "## PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hamming loss for the training data is 0.004\n",
      "The Hamming loss for the test data is 0.005\n"
     ]
    }
   ],
   "source": [
    "## Implement a binary relevance model using SVM classifiers (Naive approach to be compared with novel approaches, later)\n",
    "br_classifier = BinaryRelevance(\n",
    "    classifier = SVC(C = 1, kernel = 'rbf')\n",
    ")\n",
    "\n",
    "#br_classifier.fit(X_sepPCs_train, Y_train)\n",
    "\n",
    "#br_train_preds = br_classifier.predict(X_sepPCs_train).toarray() ## -- Making predictions takes some time. \n",
    "#br_test_preds = br_classifier.predict(X_sepPCs_test).toarray()      ## Instead, load the predictions from 'SVM_based_preds.npz', on next line.\n",
    "\n",
    "npzfile = npzfile = np.load(\"SVM_based_preds.npz\", allow_pickle = True)\n",
    "br_train_preds = npzfile[\"br_train_preds\"]\n",
    "br_test_preds = npzfile[\"br_test_preds\"]\n",
    "\n",
    "print (f\"The Hamming loss for the training data is {metrics.hamming_loss(Y_train, br_train_preds):.3f}\")\n",
    "print (f\"The Hamming loss for the test data is {metrics.hamming_loss(Y_test, br_test_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Save the SVM based predictions\n",
    "outfile = \"SVM_based_preds\"\n",
    "#np.savez_compressed(outfile, br_train_preds = br_train_preds,\n",
    "#                             br_test_preds = br_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'GridSearchcv()' returns NaNs -- Implement grid search 'by hand' (OR IMPORT GRIDSEARCH DATA IN NEXT CELL)\n",
    "C_list = list(np.arange(2, 22, 2))\n",
    "gridSearch_df = pd.DataFrame({'C' : C_list, 'Hamming-Loss' : np.zeros(len(C_list))})\n",
    "count = 0\n",
    "for C in C_list:\n",
    "    br_classifier = BinaryRelevance(classifier = SVC(C = C, kernel = 'rbf'))\n",
    "    br_classifier.fit(X_sepPCs_train, Y_train)\n",
    "  \n",
    "    br_test_preds = br_classifier.predict(X_sepPCs_test).toarray()     \n",
    "    gridSearch_df.loc[count, 'Hamming-Loss'] = metrics.hamming_loss(Y_test, br_test_preds)\n",
    "    count += 1\n",
    "gridSearch_df.to_json('SVM_bestModel_preds.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0a9d4_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >C</th>        <th class=\"col_heading level0 col1\" >Hamming-Loss</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_0a9d4_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "                        <td id=\"T_0a9d4_row0_col1\" class=\"data row0 col1\" >0.004560</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "                        <td id=\"T_0a9d4_row1_col1\" class=\"data row1 col1\" >0.004446</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row2_col0\" class=\"data row2 col0\" >6</td>\n",
       "                        <td id=\"T_0a9d4_row2_col1\" class=\"data row2 col1\" >0.004413</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row3_col0\" class=\"data row3 col0\" >8</td>\n",
       "                        <td id=\"T_0a9d4_row3_col1\" class=\"data row3 col1\" >0.004369</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row4_col0\" class=\"data row4 col0\" >10</td>\n",
       "                        <td id=\"T_0a9d4_row4_col1\" class=\"data row4 col1\" >0.004350</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row5_col0\" class=\"data row5 col0\" >12</td>\n",
       "                        <td id=\"T_0a9d4_row5_col1\" class=\"data row5 col1\" >0.004354</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row6_col0\" class=\"data row6 col0\" >14</td>\n",
       "                        <td id=\"T_0a9d4_row6_col1\" class=\"data row6 col1\" >0.004332</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row7_col0\" class=\"data row7 col0\" >16</td>\n",
       "                        <td id=\"T_0a9d4_row7_col1\" class=\"data row7 col1\" >0.004343</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row8_col0\" class=\"data row8 col0\" >18</td>\n",
       "                        <td id=\"T_0a9d4_row8_col1\" class=\"data row8 col1\" >0.004380</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_0a9d4_row9_col0\" class=\"data row9 col0\" >20</td>\n",
       "                        <td id=\"T_0a9d4_row9_col1\" class=\"data row9 col1\" >0.004420</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef1b8c4130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: 14. Best validation Hamming loss:  0.004\n"
     ]
    }
   ],
   "source": [
    "gridSearch_df = pd.read_json('SVM_bestModel_preds.json')\n",
    "display(gridSearch_df.style.hide_index())\n",
    "best_index_br = np.argmin(gridSearch_df[\"Hamming-Loss\"])\n",
    "best_parameters_br = gridSearch_df[\"C\"][best_index_br]\n",
    "best_params_validation_HL = gridSearch_df['Hamming-Loss'][best_index_br]\n",
    "print(f\"Best parameters: {best_parameters_br}. Best validation Hamming loss: {best_params_validation_HL : 0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Autoencoder Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hamming loss for the training data is 0.007\n",
      "The Hamming loss for the test data is 0.007\n"
     ]
    }
   ],
   "source": [
    "## Implement a binary relevance model using KNN classifiers (Naive approach to be compared with ML-KNN, later)\n",
    "br_classifier = BinaryRelevance(\n",
    "    classifier = SVC(C = 1, kernel = 'rbf')\n",
    ")\n",
    "\n",
    "br_classifier.fit(encoded_train, Y_train)\n",
    "\n",
    "br_train_preds = br_classifier.predict(encoded_train).toarray() #-- Making predictions takes some time. \n",
    "br_test_preds = br_classifier.predict(encoded_test).toarray()      #Instead, load the predictions from 'kNN_based_preds.npz', on next line.\n",
    "\n",
    "#npzfile = npzfile = np.load(\"SVM_based_preds_encoded.npz\", allow_pickle = True)\n",
    "#br_train_preds = npzfile[\"br_train_preds\"]\n",
    "#br_test_preds = npzfile[\"br_test_preds\"]\n",
    "\n",
    "print (f\"The Hamming loss for the training data is {metrics.hamming_loss(Y_train, br_train_preds):.3f}\")\n",
    "print (f\"The Hamming loss for the test data is {metrics.hamming_loss(Y_test, br_test_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Save the SVM based predictions\n",
    "outfile = \"SVM_based_preds_encoded\"\n",
    "#np.savez_compressed(outfile, br_train_preds = br_train_preds,\n",
    "#                             br_test_preds = br_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'GridSearchcv()' returns NaNs -- Implement grid search 'by hand' (OR IMPORT GRIDSEARCH DATA IN NEXT CELL)\n",
    "#C_list = list(np.arange(2, 22, 2))\n",
    "#gridSearch_df = pd.DataFrame({'C' : C_list, 'Hamming-Loss' : np.zeros(len(C_list))})\n",
    "#count = 0\n",
    "#for C in C_list:\n",
    "#    br_classifier = BinaryRelevance(classifier = SVC(C = C, kernel = 'rbf'))\n",
    "#    br_classifier.fit(encoded_train, Y_train)\n",
    "  \n",
    "#    br_test_preds = br_classifier.predict(encoded_test).toarray()     \n",
    "#    gridSearch_df.loc[count, 'Hamming-Loss'] = metrics.hamming_loss(Y_test, br_test_preds)\n",
    "#    count += 1\n",
    "#gridSearch_df.to_json('SVM_bestModel_preds_encoded.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4f6eb_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >C</th>        <th class=\"col_heading level0 col1\" >Hamming-Loss</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_4f6eb_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "                        <td id=\"T_4f6eb_row0_col1\" class=\"data row0 col1\" >0.006982</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "                        <td id=\"T_4f6eb_row1_col1\" class=\"data row1 col1\" >0.006790</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row2_col0\" class=\"data row2 col0\" >6</td>\n",
       "                        <td id=\"T_4f6eb_row2_col1\" class=\"data row2 col1\" >0.006731</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row3_col0\" class=\"data row3 col0\" >8</td>\n",
       "                        <td id=\"T_4f6eb_row3_col1\" class=\"data row3 col1\" >0.006654</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row4_col0\" class=\"data row4 col0\" >10</td>\n",
       "                        <td id=\"T_4f6eb_row4_col1\" class=\"data row4 col1\" >0.006628</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row5_col0\" class=\"data row5 col0\" >12</td>\n",
       "                        <td id=\"T_4f6eb_row5_col1\" class=\"data row5 col1\" >0.006581</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row6_col0\" class=\"data row6 col0\" >14</td>\n",
       "                        <td id=\"T_4f6eb_row6_col1\" class=\"data row6 col1\" >0.006551</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row7_col0\" class=\"data row7 col0\" >16</td>\n",
       "                        <td id=\"T_4f6eb_row7_col1\" class=\"data row7 col1\" >0.006544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row8_col0\" class=\"data row8 col0\" >18</td>\n",
       "                        <td id=\"T_4f6eb_row8_col1\" class=\"data row8 col1\" >0.006496</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4f6eb_row9_col0\" class=\"data row9 col0\" >20</td>\n",
       "                        <td id=\"T_4f6eb_row9_col1\" class=\"data row9 col1\" >0.006466</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef1ebf0e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: 20. Best validation Hamming loss:  0.006\n"
     ]
    }
   ],
   "source": [
    "gridSearch_df = pd.read_json('SVM_bestModel_preds_encoded.json')\n",
    "display(gridSearch_df.style.hide_index())\n",
    "best_index_br = np.argmin(gridSearch_df[\"Hamming-Loss\"])\n",
    "best_parameters_br = gridSearch_df[\"C\"][best_index_br]\n",
    "best_params_validation_HL_encoded = gridSearch_df['Hamming-Loss'][best_index_br]\n",
    "print(f\"Best parameters: {best_parameters_br}. Best validation Hamming loss: {best_params_validation_HL_encoded : 0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA</th>\n",
       "      <th>Autoencoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Constant Threshold</th>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.006466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PCA  Autoencoder\n",
       "Constant Threshold  0.004332     0.006466"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'PCA' : [best_params_validation_HL],\n",
    "                           'Autoencoder' : [best_params_validation_HL_encoded]}, \n",
    "                          index = ['Constant Threshold'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_json('SVM_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Zhang, ML., Li, YK., Liu, XY. et al. Binary relevance for multi-label learning: an overview. Front. Comput. Sci. 12, 191–202 (2018). https://doi.org/10.1007/s11704-017-7031-7\n",
    "\n",
    "Luaces, O., Díez, J., Barranquero, J. et al. Binary relevance efficacy for multilabel classification. Prog Artif Intell 1, 303–313 (2012). https://doi.org/10.1007/s13748-012-0030-x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
